# Análise de Impacto Ético

<p align="justify">&emsp;&emsp; Com o avanço rápido da tecnologia e­ a maior disponibilidade de dados, a análise de­ Big Data tem um grande potencial para ofe­recer novos insights e inovação. No contexto do projeto de Big Data com a CPTM (Companhia Paulista de Trens Metropolitanos), essa análise pode gerar melhorias significativas na gestão de falhas e ocorrências, contribuindo para otimizar o desempenho do sistema ferroviário. Porém, e­sse avanço também traz desafios éticos que pre­cisam de atenção, pois usar grandes volume­s de dados de forma inadequada pode­ levar a consequências sociais e individuais ne­gativas. É importante pensar sobre o uso ético e­ responsável desse­s dados, especialmente­ em áreas como privacidade, e­quidade, transparência, responsabilidade social e­ mitigação de vieses. A análise­ de impacto ético em Big Data visa abordar esse­s temas para garantir que práticas de cole­ta, armazenamento e inte­rpretação de dados sigam princípios éticos e re­gulamentações atuais. O texto aborda tópicos como privacidade­ e proteção de dados, e­quidade e justiça, transparência e conse­ntimento, responsabilidade social, e­ vieses e discriminação.</p>

## 1. Privacidade e Proteção de Dados

<p align="justify">&emsp;&emsp;A privacidade de dados é um tema que ganha cada vez mais importância no mundo digital. Em essência, ela trata de como cada pessoa pode manter o controle sobre suas informações pessoais. Imagine que seus dados como e-mails, biometria ou número de cartão de crédito são realmente seus, e você deveria ter a palavra final sobre como eles são coletados, guardados e usados pelas empresas.</p>

<p align="justify">&emsp;&emsp;Hoje em dia, as empresas precisam pedir o consentimento dos usuários antes de fazer qualquer coisa com seus dados, respeitando assim uma série de direitos de privacidade. Isso não só protege os dados das pessoas, mas também resguarda a própria organização de possíveis problemas legais e ataques cibernéticos. Cumprir com as regulamentações, como o famoso GDPR na Europa e a LGPD no Brasil, tornou-se essencial. A Lei Geral de Proteção de Dados Pessoais (LGPD), sancionada no Brasil em 2018 e em vigor desde 2020, estabelece um marco regulatório para a proteção de dados no país. Inspirada no GDPR, a LGPD garante uma série de direitos aos titulares de dados, incluindo consentimento explícito, o direito ao acesso e à correção de informações, e a exclusão de dados pessoais quando solicitado. Mesmo onde as leis não são tão rígidas, respeitar a privacidade é uma prática que as empresas adotam cada vez mais, tanto para proteger os usuários quanto a si mesmas.</p>

<p align="justify">&emsp;&emsp;Quando se fala de privacidade de dados, é comum pensar em segurança de dados também, mas é bom lembrar que não são exatamente a mesma coisa. A privacidade é mais sobre os direitos e preferências do indivíduo, enquanto a segurança diz respeito às medidas técnicas que uma empresa toma para proteger esses dados de acessos indesejados. Em resumo: a segurança estabelece como proteger os dados, e a privacidade define quem pode acessá-los e por quais motivos.</p>

<p align="justify">&emsp;&emsp;Para garantir a privacidade dos dados, as empresas geralmente reúnem uma equipe que envolve o pessoal de áreas como jurídico, conformidade, TI e segurança cibernética. Esses profissionais desenvolvem políticas e processos para assegurar que o uso dos dados seja claro e que os usuários possam acessar e controlar suas informações com facilidade. No caso da LGPD, essa preocupação com a privacidade também implica no conceito de "privacidade por design", o que significa que a proteção de dados deve estar incorporada desde o início do desenvolvimento de sistemas e produtos, e não apenas adicionada posteriormente. Dessa forma, as empresas brasileiras são incentivadas a aplicar esse conceito em todas as suas práticas, garantindo que os dados dos usuários sejam protegidos de forma consistente.</p>

<p align="justify">&emsp;&emsp;Além disso, algumas diretrizes, como o NIST Privacy Framework e os Princípios de Práticas Justas de Informações, ajudam as empresas a se guiarem. Esses frameworks têm princípios essenciais, como o acesso (garantir que os usuários possam ver, atualizar ou corrigir suas informações), transparência (comunicar claramente quais dados estão sendo coletados e por que), e consentimento (pedir autorização antes de usar os dados e permitir que o usuário retire essa permissão a qualquer momento).</p>

<p align="justify">&emsp;&emsp;Outro ponto importante é a qualidade dos dados. Manter dados precisos e atualizados é crucial – um erro simples, como um endereço antigo, pode gerar problemas. E então temos o princípio da privacidade por design, que busca garantir que produtos e sistemas sejam criados já com a privacidade em mente. A segurança técnica também entra aqui, com práticas como criptografia e controle de acesso, tudo para proteger os dados contra acessos indesejados.</p>

<p align="justify">&emsp;&emsp;Para as empresas que lidam com grandes volumes de dados, o compromisso com a proteção e privacidade é ainda mais sério. A IDC, uma empresa de pesquisa, apontou que mais de 70% das companhias esperam trabalhar com volumes de dados ainda maiores nos próximos anos. Esse aumento destaca a necessidade de políticas fortes de proteção e privacidade, não apenas para estar em dia com as leis, mas também para aumentar a confiança dos clientes.</p>

<p align="justify">&emsp;&emsp;A conformidade regulatória é crucial nesse contexto. A privacidade é um direito reconhecido mundialmente, e países de todos os continentes têm suas próprias leis de proteção. O GDPR europeu é um dos mais rígidos, com multas pesadas para quem não cumpre as normas, e o Brasil, com a LGPD, segue uma linha semelhante, estipulando multas de até 2% do faturamento da empresa para violações de privacidade. Além de evitar problemas legais, proteger a privacidade traz um benefício competitivo. Consumidores confiam mais em empresas que respeitam seus dados, e aquelas que sofrem vazamentos podem ter grandes prejuízos de imagem. O escândalo da Cambridge Analytica, que envolveu dados do Facebook, mostrou como um descuido com a privacidade pode arranhar a reputação de uma empresa. Em contrapartida, empresas que lidam bem com a privacidade ganham pontos com seus clientes.</p>

<p align="justify">&emsp;&emsp;Com o crescimento da inteligência artificial, novos desafios de privacidade também surgem. Imagine que uma empresa insere dados confidenciais em ferramentas de IA, esses dados podem escapar do controle da organização. A Samsung, por exemplo, teve um problema desse tipo, onde informações sensíveis foram compartilhadas sem querer. O uso responsável de IA depende, portanto, de políticas de privacidade bem estabelecidas, as quais a LGPD ajuda a estruturar, exigindo que as empresas tenham um cuidado especial ao tratar dados pessoais sensíveis e confidenciais.</p>

<p align="justify">&emsp;&emsp;No final, proteger a privacidade é uma prática que vai além do cumprimento de leis; é uma forma de cuidar da confiança dos clientes. Empresas que priorizam a privacidade demonstram respeito pelo usuário, e isso faz toda a diferença no mundo atual.</p>

## 2. Equidade e Justiça

<p align="justify">&emsp;&emsp;A análise de dados deve ser conduzida de forma que promova equidade e justiça, evitando a perpetuação de desigualdades estruturais e estereótipos. Essa responsabilidade é ainda maior em projetos de Big Data, onde a exploração e o tratamento dos dados podem impactar diretamente diversas populações, muitas vezes de maneira desigual. Mesmo sem a aplicação de modelos preditivos, a forma como os dados são organizados e apresentados nas visualizações pode refletir vieses históricos. Por exemplo, em uma análise de dados sobre transporte público, a forma como os dados são segmentados e apresentados pode favorecer regiões mais privilegiadas, se não forem levados em consideração os contextos socioeconômicos das populações envolvidas. </p>

<p align="justify">&emsp;&emsp; Em um sistema de transporte público como o da CPTM, análises de dados que ignorem contextos socioeconômicos distintos podem resultar em decisões que favorecem regiões mais privilegiadas, em detrimento de áreas periféricas. A falta de uma abordagem equitativa nos dados pode ser particularmente problemática, como apontado por O'Neil (2016), que alerta para os "Weapons of Math Destruction" — algoritmos que, ao ignorar contextos específicos, amplificam as desigualdades sociais.</p> 

<p align="justify">&emsp;&emsp; Para garantir justiça, a análise de dados no nosso projeto deve ser representativa e inclusiva, considerando as diversas realidades das populações envolvidas. Em um contexto de Big Data, isso pode ser alcançado por meio da revisão contínua dos algoritmos, identificando e corrigindo possíveis vieses que possam surgir ao longo da análise dos dados. No nosso caso, é essencial adotar práticas de transparência, como documentar de forma clara como os dados são tratados e utilizados, garantindo que o processo seja compreensível e acessível para todos os membros do projeto. Além disso, podemos utilizar ferramentas como testes de viés em dados e validação cruzada de modelos, que ajudam a identificar pontos cegos que podem impactar de maneira desigual certos grupos. Como Diakopoulos (2019) aponta, a transparência algorítmica é fundamental para que os algoritmos possam ser revisados e ajustados, assegurando que as decisões baseadas em dados sejam feitas de maneira ética e justa.</p>

<p align="justify">&emsp;&emsp; Por fim, promover equidade na análise de dados no nosso projeto não é apenas uma questão ética, mas também uma estratégia importante. Em um ambiente acadêmico como o nosso, é possível criar uma relação de confiança com os envolvidos (parceiro, alunos e professores) e aumentar a aceitação dos resultados do projeto quando adotamos uma abordagem justa e transparente. Esse compromisso ético também fortalece a qualidade da pesquisa e a sustentabilidade dos nossos processos. Como Eubanks (2018) destaca em "Automating Inequality", ignorar questões de justiça social nos algoritmos pode resultar em resistência ou desconfiança em relação ao trabalho, prejudicando a credibilidade e a eficácia dos resultados obtidos.</p>

## 3. Transparência e Consentimento Informado

&emsp;&emsp; A transparência e o consentimento são dois aspectos importantíssimos para a integridade de qualquer projeto, independente de sua classificação. A relevância é ainda maior em um projeto relacionado a Big Data, no qual a quantidade de dados e informações é muito frequente e estes se tratam dos principais aspectos do projeto. 

&emsp;&emsp; Segundo a Lei Geral de Proteção de Dados (Brasil, 2018), o consentimento daquele a quem um dado se refere deve ser obtido, pois este possui controle sobre o respectivo dado. Portanto, qualquer organização deve direcionar completa atenção a informar o direcionamento e o uso dos dados coletados a todas as partes, seja de modo optativo ou obrigatório, como pela disponibilização da informação nos termos de uso apresentados e condicionados para a utilização de um serviço.

&emsp;&emsp; A respeito da transparência, são dois os principais aspectos que se relacionam com Big Data: (1) a falta da transparência ao tratar dados. Devem ser acessíveis os detalhes das análises, incluindo quais os dados processados e qual é a finalidade; (2) o excesso de transparência ao armazenar e apresentar resultados. Conforme Carvalho, Peixoto e Carvalho (2020), traz-se o conceito de “transparência indesejável”, que deve ser ao máximo evitada, pois podem haver dados sensíveis ou desnecessários que não devem ser trabalhados sem um filtro.

&emsp;&emsp; No contexto desse projeto, a transparência e o consentimento informado devem ser pontos de atenção por todas as partes envolvidas, ou seja, as três acima citadas. É importante notar que estão envolvidas, dentre outras, informações sobre passageiros, profissionais, alunos, equipamentos, empresas terceirizadas e nomes de marcas de equipamentos.

&emsp;&emsp; A fim de evitar a falta de transparência, os documentos do projeto apresentam o nome dos stakeholders envolvidos e descrições sobre os dados disponibilizados. Além disso, foram definidos os limites do escopo, as ferramentas a serem utilizadas e quais são as permissões de acesso e compartilhamento dos dados. Deste modo, qualquer uma das partes tem informação suficiente para a continuidade do desenvolvimento e usabilidade.

&emsp;&emsp; O grupo também foca em mitigar a “transparência indesejável”, mascarando dados sensíveis ou operacionais, especialmente aqueles que envolvem incidentes ou informações de passageiros, respeitando a privacidade. Além disso, qualquer dado que possa ser crítico nesse aspecto possui acesso controlado somente à equipe da CPTM e de desenvolvimento do grupo.

&emsp;&emsp; Como exemplo de aplicação prática, temos as vertentes de transparência interna e externa. Para o interno, será implementado um painel interativo de dados, com acesso restrito às informações públicas e mascaramento automático de dados sensíveis, como forma de garantir a transparência sem expor informações críticas ou pessoais. Já como externo, podemos destacar a publicação de relatórios periódicos no site da CPTM, informando sobre a utilização de dados para melhoria do serviço, e a realização de campanhas educativas sobre privacidade e proteção de dados. 

&emsp;&emsp; Vale ressaltar que o consentimento de todos os envolvidos no projeto foi obtido corretamente. A parceria entre o Inteli e a CPTM é estabelecido por contrato, assim como a relação aluno-faculdade presente. Nessa linha, todas as informações utilizadas no projeto foram previamente delimitadas conforme a autorização. A respeito de nomes de empresas e equipamentos existentes no banco de dados, todos esses são públicos e/ou parte de uma negociação acordada entre a CPTM e a respectiva empresa.

&emsp;&emsp; Ao priorizar a transparência e o consentimento informado, não somente garante-se a conformidade com boas práticas, mas também estabelece-se confiança entre todos os stakeholders. Deste modo, todos os dados são utilizados de forma ética e responsável e contribuem para que as análises realizadas gerem bons resultados para a gestão da CPTM. 

## 4. Responsabilidade Social

<p align="justify">&emsp;&emsp; A implementação de um projeto de Big Data pela CPTM, no qual o grupo Xpress analisa as tabelas de ocorrências, falhas, viagens e materiais, vai além de uma questão operacional ou de eficiência. Esse processo reflete uma abordagem mais ampla de responsabilidade social e cuidado com a prevenção de viés e discriminação nos serviços prestados. Através de uma análise ética, a CPTM pode assegurar que suas ações beneficiem a sociedade de maneira justa e igualitária.</p> 

<p align="justify">&emsp;&emsp; A responsabilidade social corporativa se refere ao compromisso de uma organização em agir de maneira ética e transparente, contribuindo para o bem-estar da sociedade e para a preservação do meio ambiente. No caso da CPTM, isso se traduz em oferecer um serviço de transporte público seguro, confiável e acessível a milhões de passageiros diariamente. O uso de Big Data não só melhora a eficiência e segurança, mas também impacta positivamente a vida dos usuários, gerando benefícios sociais significativos.</p>

<p align="justify">&emsp;&emsp; Carroll (1991) propôs a "Pirâmide da Responsabilidade Social Corporativa", que sugere que as empresas devem equilibrar suas responsabilidades econômicas, legais, éticas e filantrópicas. Para a CPTM, esses conceitos podem ser traduzidos em ações que priorizem a segurança e a qualidade dos serviços, cumprindo leis e regulamentos e buscando sempre o bem-estar social.</p> 

<p align="justify">&emsp;&emsp; Porter e Kramer (2006) destacam como a responsabilidade social pode ser integrada à estratégia corporativa, criando uma vantagem competitiva ao incorporar o impacto social nas operações da empresa. Para a CPTM, o uso de Big Data para aprimorar a segurança e o conforto dos passageiros pode fortalecer sua imagem como uma empresa comprometida com a sociedade.</p>

<p align="justify">&emsp;&emsp; A responsabilidade social da CPTM se reflete no uso consciente de Big Data, que não só aprimora a qualidade do serviço prestado, mas também contribui para benefícios sociais amplos. A análise de dados sobre ocorrências e falhas permite à empresa identificar padrões de risco e realizar manutenção preventiva, o que é essencial para garantir a segurança dos passageiros e minimizar os transtornos durante as viagens. Além disso, a análise dos dados sobre consumo e desgaste de materiais possibilita à CPTM adotar políticas mais eficientes, reduzindo desperdícios e ajudando na preservação ambiental. Esse uso de Big Data, portanto, reflete um compromisso com a sustentabilidade e com o bem-estar dos passageiros, promovendo um impacto positivo na sociedade de maneira ética e responsável.</p>

## 5. Viés e Discriminação

<p align="justify">&emsp;&emsp; A identificação e prevenção de viés e discriminação no uso de Big Data são fundamentais para garantir que os dados e algoritmos empregados pela CPTM não reforcem desigualdades ou preconceitos. Os sistemas de análise de dados podem inadvertidamente reproduzir padrões de discriminação, afetando negativamente certos grupos ou regiões de passageiros. Para a CPTM, isso significa implementar práticas de análise que assegurem uma distribuição justa dos recursos e que os serviços sejam acessíveis e equitativos para todos (assim como aprofundado acima no tópico de "Equidade e Justiça".</p> 

<p align="justify">&emsp;&emsp; Noble (2018) discute como algoritmos podem perpetuar estereótipos raciais e sexistas, criando consequências sociais negativas. A CPTM precisa estar atenta a essas questões para evitar que decisões automatizadas favoreçam certas regiões em detrimento de outras, garantindo um serviço acessível e justo para todos. Em São Paulo, isso implica assegurar que todas as zonas da cidade recebam a mesma qualidade de serviço e atendimento ao cliente.</p>

<p align="justify">&emsp;&emsp; Buolamwini e Gebru (2018) ressaltam como algoritmos de reconhecimento facial têm falhas mais frequentes ao identificar mulheres e pessoas de cor. Para a CPTM, é essencial que os algoritmos preditivos utilizados no gerenciamento de recursos considerem dados diversos e representativos para evitar viés que possa discriminar áreas periféricas ou menos favorecidas.</p>

<p align="justify">&emsp;&emsp; Para combater viés e discriminação no uso de Big Data, a CPTM deve adotar práticas que garantam uma alocação equitativa dos recursos. Isso significa que as regiões periféricas, que muitas vezes enfrentam mais desafios em termos de infraestrutura e falhas, devem receber uma quantidade proporcional de atenção e recursos, evitando que as áreas centrais sejam favorecidas de forma injusta. A análise de dados deve ser desenvolvida com foco na equidade, levando em consideração as necessidades específicas de cada zona da cidade. Além disso, ao utilizar algoritmos para a tomada de decisões, a CPTM precisa garantir a transparência no uso dos dados, divulgando publicamente as métricas e relatórios sobre como os recursos estão sendo aplicados. De modo geral, é fundamental que a CPTM implemente essas práticas para garantir que todos os passageiros sejam tratados de maneira indistinta, promovendo um sistema de transporte público acessível e igualitário para todos. </p>

## Conclusão

<p align="justify">&emsp;&emsp; A análise ética de Big Data é fundamental para garantir o avanço tecnológico responsável, respeitando princípios como privacidade, equidade e transparência. Com o aumento do uso de grandes volumes de dados, surgem desafios relacionados à proteção dos direitos individuais e à mitigação de vieses que podem comprometer a justiça e a confiança nos sistemas. Legislações como a LGPD (Lei Geral de Proteção de Dados Pessoais) no Brasil e o GDPR (Regulamento Geral de Proteção de Dados da União Europeia) são essenciais para garantir a privacidade e a segurança das informações pessoais.</p> 

<p align="justify">&emsp;&emsp; Adotar uma abordagem ética que priorize a proteção de dados sensíveis, o respeito à privacidade e a transparência nas operações ajuda as organizações a reduzir riscos e garantir conformidade legal, além de fortalecer sua reputação e promover um ambiente mais justo. O uso responsável de Big Data é, portanto, não apenas uma obrigação legal, mas uma estratégia que traz benefícios para todos.</p> 

<p align="justify">&emsp;&emsp; Para garantir a transparência e promover a confiança no uso de Big Data, são essenciais as práticas de divulgação de relatórios periódicos e o estabelecimento de canais de comunicação claros com os stakeholders. Essas ações permitem que o público compreenda como os dados são utilizados, além de demonstrar o compromisso da organização com princípios éticos e responsabilidade social. No caso da CPTM, essas medidas reforçam a legitimidade de suas operações e alinham o projeto com os valores da comunidade que atende.</p>

<p align="justify">&emsp;&emsp; Também focada em responsabilidade social, viés e discriminação, essa análise oferece uma oportunidade para a CPTM alinhar suas operações aos valores de equidade e sustentabilidade. Ao adotar práticas responsáveis na análise de dados, a empresa de transporte público aprimora seu serviço e imagem pública, além de cumprir seu dever ético de tratar todos os passageiros de forma justa. A docum entação de impacto ético, portanto, é essencial para garantir que as tecnologias utilizadas atendam aos objetivos operacionais e reforcem o compromisso da empresa com a responsabilidade social e a justiça.</p>

## Referências:

CARVALHO, Artur Potiguara; PEIXOTO, Fabiano Hartmann; CARVALHO, Fernanda Potiguara. Governança de Dados aplicada a Big Data Analytics: a necessidade de gestão dos dados em Big Data para além da LGPD. In: PINTO, Danielle Jacon Ayres; ROVER, Aires Jose; PEIXOTO, Fabiano Hartmann (Orgs.). I Encontro Virtual do CONPEDI: Direito, governança e novas tecnologias II [Recurso eletrônico on-line]. Florianópolis: CONPEDI, 2020. p. 57-74. Disponível em: http://site.conpedi.org.br/publicacoes/olpbq8u9/lxxdq7f2/nC0tdO80Ds5cd8Zv.pdf. Acesso em: 12 nov. 2024.

SANTOS, Carlos Eduardo Lessa; CARVALHO, Felipe Freire de. Privacidade e proteção de dados na era do Big Data. 2019. Trabalho de conclusão de curso (Bacharelado em Sistemas de Informação) – Universidade Federal Fluminense, Rio de Janeiro, 2019. Disponível em: https://app.uff.br/riuff/bitstream/handle/1/13054/Carlos%20Eduardo_Felipe%20Freire.pdf?sequence=1&isAllowed=y. Acesso em: 12 nov. 2024.

BRASIL. Lei nº 13.709, de 14 de agosto de 2018. Dispõe sobre a proteção de dados pessoais e altera a Lei nº 12.965, de 23 de abril de 2014 (Marco Civil da Internet). Diário Oficial da União: seção 1, Brasília, DF, 15 ago. 2018. Disponível em: https://www.planalto.gov.br/ccivil_03/_Ato2015-2018/2018/Lei/L13709.htm. Acesso em: 13 nov. 2024.

Lucidarium. A Ética na Era da Big Data. Disponível em: https://lucidarium.com.br/a-etica-na-era-da-big-data/. Acesso em: 12 Nov. 2024.

IBM. O que é privacidade de dados? Disponível em: https://www.ibm.com/br-pt/topics/data-privacy. Acesso em: 13 Nov. 2024.

CARROLL, A. B. The Pyramid of Corporate Social Responsibility: Toward the Moral Management of Organizational Stakeholders. Business Horizons, v. 34, n. 4, p. 39-48, 1991.

PORTER, M. E.; KRAMER, M. R. Strategy & Society: The Link Between Competitive Advantage and Corporate Social Responsibility. Harvard Business Review, v. 84, n. 12, p. 78-92, 2006.

NOBLE, S. U. Algorithms of Oppression: How Search Engines Reinforce Racism. New York: NYU Press, 2018.

BUOLAMWINI, J.; GEBRU, T. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of Machine Learning Research, v. 81, p. 1-15, 2018.

DIAKOPOULOS, Nicholas. Automating the News: How Algorithms Are Rewriting the Media. Cambridge: Harvard University Press, 2019.

EUBANKS, Virginia. Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. New York: St. Martin's Press, 2018.

O'NEIL, Cathy. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. New York: Crown Publishing Group, 2016.
